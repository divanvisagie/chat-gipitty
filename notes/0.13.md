## v0.3.0 Release Notes


### New Features

- **Custom API Endpoint Support**
  - Add support for specifying a custom API endpoint via the `OPENAI_API_URL` environment variable.
  - Enables compatibility with local and alternative LLMs, such as [Ollama](https://ollama.com), by pointing the client to a custom server.
  - Improved error handling—users now receive more informative messages on request failures.

- **'jarjar' Option Added**
  - Mesa called JarJar Binks! Har har! Dis new `jarjar` option, when enabled, makes da model talk just like meesa from Star Wars. Every response, full of Gungan wisdom and silly talk, oh yes! Use for da laughs, or when yousa want da AI to be extra goofy. Yousa try it, yousa gonna love it!

**Upgrade Note:**  
If you’d like to test with your own model (e.g., a local instance or third-party API), simply set the new `OPENAI_API_URL` before running `cgip`.

```sh
export OPENAI_API_URL=http://localhost:11434/v1
```

